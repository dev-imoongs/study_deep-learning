#!/usr/bin/env python
# coding: utf-8

# ### CNN(Convolutional Neural Network), í•©ì„±ê³± ì‹ ê²½ë§
# - ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ë¶„ë¥˜ ëŒ€ìƒì´ ì´ë¯¸ì§€ì—ì„œ ê³ ì •ëœ ìœ„ì¹˜ì— ìˆì§€ ì•Šê³  ë¶„ë¥˜ ëŒ€ìƒì´ ì´ë¯¸ì§€ì˜ ì–´ë””ì— ìˆì„ì§€ ëª¨ë¥´ëŠ” ê²½ìš°ê°€ ëŒ€ë¶€ë¶„ì´ë‹¤.  
# - ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ì„œëŠ”, ì´ë¯¸ì§€ì˜ ê° featureë“¤ì„ ê·¸ëŒ€ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, CNNìœ¼ë¡œ íŒ¨í„´ì„ ì¸ì‹í•œ ë’¤ í•™ìŠµí•´ì•¼ í•œë‹¤.
# 
# <div style="display: flex; width:70%; margin-bottom: 30px;">
#     <div>
#         <img src="./images/dogs01.png" width="500" style="margin-left: 20px">
#     </div>
#     <div>
#         <img src="./images/dogs02.png" width="720" style="margin-left: 80px">
#     </div>
# </div>
# 
# - ì´ë¯¸ì§€ì˜ í¬ê¸°ê°€ ì»¤ì§ˆ ìˆ˜ë¡ êµ‰ì¥íˆ ë§ì€ Weightê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ë¶„ë¥˜ê¸°ì— ë°”ë¡œ ë„£ì§€ ì•Šê³ , ì´ë¥¼ ì‚¬ì „ì— ì¶”ì¶œ ë° ì¶•ì†Œí•´ì•¼ í•œë‹¤.
# <div style="display: flex; width:70%; margin-top: 10px;">
#     <div>
#         <img src="./images/tiger.png" width="600" style="margin-left: 0; margin-top: 50px">
#     </div>
#     <div>
#         <img src="./images/tiger_dnn.png" width="700" style="margin-left: 50px">
#     </div>
# </div>
# 
# - CNNì€ ì¸ê°„ì˜ ì‹œì‹ ê²½ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ê¸°ìˆ ë¡œì„œ, ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•œë‹¤.
# - Feature Extractionì„ í†µí•´ ê° ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©´ì„œ, í•¨ì¶•ëœ ì´ë¯¸ì§€ ì¡°ê°ìœ¼ë¡œ ë¶„ë¦¬ë˜ê³  ê° ì´ë¯¸ì§€ ì¡°ê°ì„ í†µí•´ ì´ë¯¸ì§€ì˜ íŒ¨í„´ì„ ì¸ì‹í•  ìˆ˜ ìˆë‹¤.
# <img src="./images/cnn01.png" width="700" style="margin-left: 0; margin-bottom: 20px">
# 
# - CNNì€ ë¶„ë¥˜í•˜ê¸°ì— ì í•©í•œ ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê³ , ìµœì ì˜ featureë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ìµœì ì˜ Weightì™€ Filterë¥¼ ê³„ì‚°í•œë‹¤.
# <img src="./images/cnn02.png" width="500" style="margin-left: 50px">
# ---
# 
# #### Filter
# - ì¼ë°˜ì ìœ¼ë¡œ ì •ë°© í–‰ë ¬ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì›ë³¸ ì´ë¯¸ì§€ì— ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ìƒˆë¡œìš´ í”½ì…€ê°’ì„ ë§Œë“¤ë©´ì„œ ì ìš©í•œë‹¤.
# - ë³´í†µì€ ì‚¬ìš©ìê°€ ëª©ì ì— ë§ëŠ” íŠ¹ì • í•„í„°ë¥¼ ìŠ¤ìŠ¤ë¡œ ë§Œë“¤ê±°ë‚˜ ê¸°ì¡´ì— ì„¤ê³„ëœ ë‹¤ì–‘í•œ í•„í„°ë¥¼ ì„ íƒí•˜ì—¬ ì´ë¯¸ì§€ì— ì ìš©í•˜ì§€ë§Œ,  
# CNNì€ ìµœì ì˜ í•„í„° ê°’ì„ í•™ìŠµì„ í†µí•´ ìŠ¤ìŠ¤ë¡œ ìµœì í™” í•œë‹¤.
# <img src="./images/filter.png" width="500" style="margin-left: 0;">
# <img src="./images/filter.gif" width="400" style="margin-left: -20px; margin-top: -30px; margin-bottom: -50px">
# 
# - í•„í„° í•˜ë‚˜ ë‹¹, ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ ë§Œí¼ Kernelì´ ì¡´ì¬í•˜ê³ , ê° ì±„ë„ì— í• ë‹¹ëœ í•„í„°ì˜ ì»¤ë„ì„ ì ìš©í•˜ì—¬ ì¶œë ¥ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œë‹¤.
# - ì¶œë ¥ Feature Mapì˜ ê°œìˆ˜ëŠ” í•„í„°ì˜ ê°œìˆ˜ì™€ ë™ì¼í•˜ë‹¤.
# <img src="./images/filter_channel.gif" width="500" style="margin-left: -10px">
# 
# #### Kernel
# - filter ì•ˆì— 1 ~ nê°œì˜ ì»¤ë„ì´ ì¡´ì¬í•œë‹¤. ì»¤ë„ì˜ ê°œìˆ˜ëŠ” ë°˜ë“œì‹œ ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ì™€ ë™ì¼í•´ì•¼ í•œë‹¤.
# - Kernel SizeëŠ” ë©´ì (ê°€ë¡œxì„¸ë¡œ)ì„ ì˜ë¯¸í•˜ë©° ê°€ë¡œì™€ ì„¸ë¡œëŠ” ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ ë³´í†µì€ ì¼ì¹˜ ì‹œí‚¨ë‹¤.
# - Kernel í¬ê¸°ê°€ í¬ë©´ í´ ìˆ˜ë¡ ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ë” ë§ì€ Feature ì •ë³´ë¥¼ ê°€ì ¸ ì˜¬ ìˆ˜ ìˆì§€ë§Œ,  
# í° ì‚¬ì´ì¦ˆì˜ Kernelë¡œ Convolution ì—°ì‚°ì„ í•  ê²½ìš° í›¨ì”¬ ë” ë§ì€ ì—°ì‚°ëŸ‰ê³¼ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ë‹¤.
# <img src="./images/kernel.gif" width="500" style="margin-left: -20px">
# 
# #### Filter and Kernel
# <img src="./images/filter_kernel01.png" width="500" style="margin-left: 0px">
# <img src="./images/filter_kernel02.png" width="500" style="margin-left: 0px">  
# 
# #### Stride
# - ì…ë ¥ ì´ë¯¸ì§€ì— Convolution Filterë¥¼ ì ìš©í•  ë•Œ Sliding Windowê°€ ì´ë™í•˜ëŠ” ê°„ê²©ì„ ì˜ë¯¸í•œë‹¤.
# - ê¸°ë³¸ strideëŠ” 1ì´ì§€ë§Œ, 2ë¥¼ ì ìš©í•˜ë©´ ì…ë ¥ feature map ëŒ€ë¹„ ì¶œë ¥ feature mapì˜ í¬ê¸°ê°€ ëŒ€ëµ ì ˆë°˜ìœ¼ë¡œ ì¤„ì–´ë“ ë‹¤.
# - strideë¥¼ í‚¤ìš°ë©´ featureë¥¼ ì†ì‹¤í•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ì§€ë§Œ, ì˜¤íˆë ¤ ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì„ ì œê±°í•˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì ¸ ì˜¬ ìˆ˜ ìˆê³  Convolution ì—°ì‚° ì†ë„ë¥¼ í–¥ìƒ ì‹œí‚¨ë‹¤.
# <div style="display: flex; width:70%; margin-top: 10px;">
#     <div>
#         <img src="./images/stride01.gif" width="600" style="margin-left: 0; margin-top: 0">
#     </div>
#     <div>
#         <img src="./images/stride02.gif" width="600" style="margin-left: 50px">
#     </div>
# </div>
# 
# #### Padding
# - Filterë¥¼ ì ìš©í•˜ì—¬ Convolution ì—°ì‚° ìˆ˜í–‰ ì‹œ ì¶œë ¥ Feature Mapì´ ì…ë ¥ Feature Map ëŒ€ë¹„ ê³„ì†ì ìœ¼ë¡œ ì‘ì•„ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ Paddingì„ ì ìš©í•œë‹¤.
# - Filter ì ìš© ì „, ì…ë ¥ Feature Mapì˜ ìƒí•˜ì¢Œìš° ëì— ê°ê° ì—´ê³¼ í–‰ì„ ì¶”ê°€ í•œ ë’¤ , 0 ê°’ìœ¼ë¡œ ì±„ì›Œ, ì…ë ¥ Feature map ì‚¬ì´ì¦ˆë¥¼ ì¦ê°€ ì‹œí‚¨ë‹¤.
# - ì¶œë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ ì§ì ‘ ê³„ì‚°í•  í•„ìš” ì—†ì´ "same"ì´ë¼ëŠ” ê°’ì„ í†µí•´ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë§ì¶œ ìˆ˜ ìˆë‹¤.
# <img src="./images/padding.gif" width="600" style="margin-left: 0">
# 
# #### Pooling
# - Convolution ì—°ì‚°ì´ ì ìš©ëœ Feature mapì˜ ì¼ì • ì˜ì—­ ë³„ë¡œ í•˜ë‚˜ì˜ ê°’ì„ ì¶”ì¶œí•˜ì—¬ Feature mapì˜ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì¸ë‹¤(sub sampling). 
# - ë³´í†µì€ Convolution -> ReLU activation -> Pooling ìˆœì„œë¡œ ì ìš©í•œë‹¤.
# - ë¹„ìŠ·í•œ featureë“¤ì´ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ì—ì„œ ìœ„ì¹˜ê°€ ë‹¬ë¼ì§€ë©´ì„œ ë‹¤ë¥´ê²Œ í•´ì„ë˜ëŠ” í˜„ìƒì„ ì¤‘í™” ì‹œí‚¬ ìˆ˜ ìˆê³ ,  
# Feature Mapì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ê¸° ë•Œë¬¸ì—, ì—°ì‚° ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.
# - Max Poolingê³¼ Average Poolingì´ ìˆìœ¼ë©°, Max Poolingì€ ì¤‘ìš”ë„ê°€ ê°€ì¥ ë†’ì€ featureë¥¼ ì¶”ì¶œí•˜ê³ , Average Poolingì€ ì „ì²´ë¥¼ ë²„ë¬´ë ¤ì„œ ì¶”ì¶œí•œë‹¤.
# <img src="./images/pooling.gif" width="450" style="margin-left: -30px; margin-top: 20px; margin-bottom: 30px">
# 
# #### ğŸš© ì •ë¦¬
# - Strideë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒê³¼ Poolingì„ ì ìš©í•˜ëŠ” ê²ƒì€ ì¶œë ¥ Feature Mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ”ë° ì‚¬ìš©í•œë‹¤.
# - Convolution ì—°ì‚°ì„ ì§„í–‰í•˜ë©´ì„œ Feature Mapì˜ í¬ê¸°ë¥¼ ì¤„ì´ë©´, ìœ„ì¹˜ ë³€í™”ì— ë”°ë¥¸ featureì˜ ì˜í–¥ë„ë„ ì¤„ì–´ì„œ, ì˜¤ë²„í”¼íŒ… ê°ì†Œ ë“±ì˜ ì¥ì ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.
# - Poolingì˜ ê²½ìš° íŠ¹ì • ìœ„ì¹˜ì˜ featureê°’ì´ ì†ì‹¤ ë˜ëŠ” ì´ìŠˆ ë“±ìœ¼ë¡œ ì¸í•˜ì—¬ ìµœê·¼ Advanced CNNì—ì„œëŠ” ë§ì´ ì‚¬ìš©ë˜ê³  ìˆì§€ ì•ŠëŠ”ë‹¤.
# - ê³¼ê±° LeNet, AlexNet, VGGì˜ ê²½ìš°ëŠ” CNN(Stride/Padding) -> Activation -> Poolingìœ¼ë¡œ ì´ì–´ì§€ëŠ” ì „í˜•ì ì¸ êµ¬ì¡°ë¥¼ ê°–ì¶”ì—ˆìœ¼ë‚˜  
# ì´í›„ ë°œí‘œë˜ëŠ” ë…¼ë¬¸ ë“±ì—ì„œ Strideë¡œ Feature Map í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì´ Pooling ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ê³  í•œë‹¤.
# - ResNetë¶€í„° ì´ì–´ì§€ëŠ” ìµœê·¼ CNNì—ì„œëŠ” ìµœëŒ€í•œ Poolingì„ ìì œí•˜ê³  Strideë¥¼ ì´ìš©í•˜ì—¬ Networkì„ êµ¬ì„±í•˜ëŠ” ê²½í–¥ì´ ê°•í•´ì§€ê³  ìˆë‹¤.
# - CNNì€ Feature Extractorì™€ Classifierë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.
# <img src="./images/cnn03.png" width="850" style="margin-left: -20px; margin-bottom: 20px;">
# - Classifierì—ì„œëŠ” Fully Connected Layerì˜ ì§€ë‚˜ì¹œ ì—°ê²°ë¡œ ì¸í•´ ë§ì€ íŒŒë¼ë¯¸í„°(Weight)ê°€ ìƒì„±ë˜ë¯€ë¡œ ì˜¤íˆë ¤ ì˜¤ë²„ í”¼íŒ…ì„ ê°€ì ¸ ì˜¬ ìˆ˜ ìˆê²Œ ëœë‹¤.  
# - Dropoutì„ ì‚¬ìš©í•´ì„œ Layerê°„ ì—°ê²°ì„ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë©° ì˜¤ë²„ í”¼íŒ…ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.
# <img src="./images/dropout.png" width="850" style="margin: 20px; margin-left: -10px;">

# In[2]:


import numpy as np
import pandas as pd
import os


# ##### Conv2D

# In[3]:


from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D
from tensorflow.keras.models import Model

INPUT_SIZE = 28

input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))
x = Conv2D(filters=4, kernel_size=(3, 3), strides=(1, 1), padding="same", activation='relu')(input_tensor)
print(type(x), x, sep='\n')


# ##### Pooling

# In[4]:


input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))
x = Conv2D(filters=12, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)
# MaxPoolingì— ì „ë‹¬í•œ ìˆ˜ë¡œ ê¸°ì¡´ pxì„ ë‚˜ëˆ„ë©´ ìµœì¢… pxì´ ë‚˜ì˜¨ë‹¤.
x = MaxPooling2D((3, 3))(x)
print(type(x), x, sep='\n')


# ##### CNN

# In[6]:


from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D
from tensorflow.keras.models import Model

INPUT_SIZE = 28

input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))

# Input * kernel * filter = param
x = Conv2D(filters=10, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)
x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)
output = MaxPooling2D(2)(x)

model = Model(inputs=input_tensor, outputs=output)
model.summary()


# In[9]:


from tensorflow.keras.layers import Dense, Flatten

input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))
x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)
x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)
x = MaxPooling2D(2)(x)

x = Flatten()(x)
x = Dense(100, activation='relu')(x)
output = Dense(10, activation='softmax')(x)
model = Model(inputs=input_tensor, outputs=output)
model.summary()


# In[12]:


import numpy as np
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

def get_preprocessed_data(images, targets):
    images = np.array(images / 255.0, dtype=np.float32)
    targets = np.array(targets, dtype=np.float32)
    
    return images, targets

def get_preprocessed_ohe(images, targets):
    images, targets = get_preprocessed_data(images, targets)
    oh_targets = to_categorical(targets)
    
    return images, oh_targets

def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):
    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)
    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)
    
    train_train_images, validation_images, train_train_oh_targets, validation_targets = \
    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)
    
    return (train_train_images, train_train_oh_targets), (validation_images, validation_targets), (test_images, test_oh_targets)


# In[16]:


from tensorflow.keras.datasets import fashion_mnist

(train_images, train_targets), (test_images, test_targets) = fashion_mnist.load_data()

print('before reshape: ', train_images.shape, test_images.shape)

# ì±„ë„ ìˆ˜ë¥¼ ê¼­ ë„£ì–´ì£¼ì!
train_images = np.reshape(train_images, (60000, 28, 28, 1))
test_images = np.reshape(test_images, (10000, 28, 28, 1))

print('after reshape: ', train_images.shape, test_images.shape)

(train_train_images, train_train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \
get_train_valid_test(train_images, train_targets, test_images, test_targets)

print(train_train_images.shape, train_train_oh_targets.shape)
print(validation_images.shape, validation_oh_targets.shape)
print(test_images.shape, test_oh_targets.shape)


# In[18]:


from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import Accuracy

model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])


# In[19]:


history = model.fit(x=train_train_images, y=train_train_oh_targets, batch_size=256, epochs=20, validation_data=(validation_images, validation_oh_targets))


# In[20]:


model.evaluate(test_images, test_oh_targets, batch_size=256, verbose=1)


# In[21]:


import matplotlib.pyplot as plt

def show_history(history):
    plt.plot(history.history['acc'], label='train')
    plt.plot(history.history['val_acc'], label='validation')
    plt.legend()

show_history(history)


# ##### Dropout

# In[28]:


from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import Accuracy

INPUT_SIZE = 28

input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE, 1))
x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')(input_tensor)
x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)
x = MaxPooling2D(2)(x)

x = Flatten()(x)
x = Dropout(rate=0.5)(x)
x = Dense(100, activation='relu')(x)
output = Dense(10, activation='softmax')(x)


model = Model(inputs=input_tensor, outputs=output)
model.summary()
model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])


# In[ ]:


history = model.fit(x=train_train_images, y=train_train_oh_targets, batch_size=256, epochs=20, validation_data=(validation_images, validation_oh_targets))


# In[ ]:


model.evaluate(test_images, test_oh_targets, batch_size=256, verbose=1)


# In[ ]:


import matplotlib.pyplot as plt

def show_history(history):
    plt.plot(history.history['acc'], label='train')
    plt.plot(history.history['val_acc'], label='validation')
    plt.legend()

show_history(history)

